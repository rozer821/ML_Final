{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Template is created to make grading fair and straightforward. Anything not in the place as mentioned in the template would not be graded.\n",
    "\n",
    "<font color='red'> # NOTE: We would run the notebook through a Plagiarism Checker. If it is found to be copied, your work would not be graded, and the incident would be highlighted to NYU Authorities. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, neighbors, preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    " \n",
    "#read data\n",
    "df = pd.read_csv('qudditch_training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Datatype Conversion From Numeric to categoric and Vice-versa. (If ANY)\n",
    "#### Feature Reduction or extraction. (If ANY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name:  double_eight_loop Uniques:  1\n",
      "Column Name:  finbourgh_flick Uniques:  1\n",
      "Column Name:  transylvanian_tackle Uniques:  1\n"
     ]
    }
   ],
   "source": [
    "#replace gender with numeric\n",
    "df.replace('Female',1,inplace=True)\n",
    "df.replace('Male',0,inplace=True)\n",
    "df['weight'].replace({'>200': 200, '[0-25)': 0,'[25-50)': 25,'[50-75)': 50,'[75-100)': 75,'[100-125)': 100,'[125-150)': 120,'[150-175)': 150,'[175-200)': 175,'?':np.NaN},inplace=True)\n",
    "df = df[df.gender != 'Unknown/Invalid']\n",
    "df = df[df.house != '?']\n",
    "\n",
    "\n",
    "\n",
    "# Finding columns with no information\n",
    "useless = []\n",
    "for i in df.columns:\n",
    "    l = len(df[i].unique())\n",
    "    if l<2:\n",
    "        useless.append(i)\n",
    "        print(\"Column Name: \",i,\"Uniques: \",l)\n",
    "df.drop(useless,axis=1,inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name:  power_play Uniques:  2\n",
      "['No' 'Steady']\n",
      "Column Name:  starfish_and_stick Uniques:  2\n",
      "['No' 'Steady']\n",
      "Column Name:  chelmondiston_charge Uniques:  2\n",
      "['No' 'Steady']\n",
      "Column Name:  plumpton_pass Uniques:  2\n",
      "['No' 'Steady']\n",
      "Column Name:  porskoff_ploy Uniques:  2\n",
      "['No' 'Steady']\n",
      "Column Name:  woollongong_shimmy Uniques:  2\n",
      "['No' 'Steady']\n",
      "Column Name:  change Uniques:  2\n",
      "['No' 'Ch']\n",
      "Column Name:  snitch_caught Uniques:  2\n",
      "['No' 'Yes']\n",
      "Column Name:  quidditch_league_player Uniques:  2\n",
      "['NO' 'YES']\n"
     ]
    }
   ],
   "source": [
    "#change all feature that only has two items into 0,1 which all no indicated by 0 and other indicated by 1 \n",
    "bi = []\n",
    "for i in df.columns.drop('gender'):\n",
    "    l = len(df[i].unique())\n",
    "    if l == 2:\n",
    "        bi.append(i)\n",
    "        print(\"Column Name: \",i,\"Uniques: \",l)\n",
    "        print(df[i].unique())\n",
    "        \n",
    "for i in bi:\n",
    "    df[i].replace(df[i].unique()[0],0,inplace=True)\n",
    "    df[i].replace(df[i].unique()[1],1,inplace=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makesure all columns have more than 2 value\n",
    "useless = []\n",
    "for i in df.columns:\n",
    "    l = len(df[i].unique())\n",
    "    if l<2:\n",
    "        useless.append(i)\n",
    "        print(\"Column Name: \",i,\"Uniques: \",l)\n",
    "df.drop(useless,axis=1,inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name:  id_num Uniques:  99002\n",
      "Column Name:  player_id Uniques:  69405\n",
      "Column Name:  house Uniques:  5\n",
      "Column Name:  age Uniques:  10\n",
      "Column Name:  weight Uniques:  10\n",
      "Column Name:  foul_type_id Uniques:  8\n",
      "Column Name:  game_move_id Uniques:  26\n",
      "Column Name:  penalty_id Uniques:  17\n",
      "Column Name:  game_duration Uniques:  14\n",
      "Column Name:  player_code Uniques:  17\n",
      "Column Name:  move_specialty Uniques:  73\n",
      "Column Name:  num_game_moves Uniques:  118\n",
      "Column Name:  num_game_losses Uniques:  7\n",
      "Column Name:  num_practice_sessions Uniques:  75\n",
      "Column Name:  num_games_satout Uniques:  39\n",
      "Column Name:  num_games_injured Uniques:  32\n",
      "Column Name:  num_games_notpartof Uniques:  21\n",
      "Column Name:  player_type Uniques:  9\n",
      "Column Name:  num_games_won Uniques:  16\n",
      "Column Name:  snitchnip Uniques:  4\n",
      "Column Name:  stooging Uniques:  4\n",
      "Column Name:  body_blow Uniques:  4\n",
      "Column Name:  checking Uniques:  4\n",
      "Column Name:  dopplebeater_defence Uniques:  4\n",
      "Column Name:  hawkshead_attacking_formation Uniques:  4\n",
      "Column Name:  no_hands_tackle Uniques:  4\n",
      "Column Name:  sloth_grip_roll Uniques:  4\n",
      "Column Name:  spiral_dive Uniques:  4\n",
      "Column Name:  twirl Uniques:  4\n",
      "Column Name:  wronski_feint Uniques:  4\n",
      "Column Name:  zig-zag Uniques:  4\n",
      "Column Name:  bludger_backbeat Uniques:  4\n",
      "Column Name:  dionysus_dive Uniques:  3\n",
      "Column Name:  reverse_pass Uniques:  4\n",
      "Column Name:  parkins_pincer Uniques:  4\n"
     ]
    }
   ],
   "source": [
    "#dummie part\n",
    "cat = []\n",
    "for i in df.columns:\n",
    "    l = len(df[i].unique())\n",
    "    if l > 2:\n",
    "        cat.append(i)\n",
    "        print(\"Column Name: \",i,\"Uniques: \",l)\n",
    "#         print(df[i].unique())\n",
    "cat.remove('player_id')\n",
    "cat.remove('weight')\n",
    "cat.remove('player_code')\n",
    "cat.remove('move_specialty')\n",
    "\n",
    "dummie = pd.get_dummies(df[cat])\n",
    "dummie = pd.concat([dummie,df[bi]],axis=1)\n",
    "dummie = pd.concat([dummie,df['gender']],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values. (If ANY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get single colunm\n",
    "wei = df['weight']\n",
    "player = df['player_code']\n",
    "spc = df['move_specialty']\n",
    "\n",
    "temp_weight = pd.concat([dummie,wei],axis=1)\n",
    "temp_play = pd.concat([dummie,player],axis=1)\n",
    "temp_play.replace('?',np.NaN,inplace=True)\n",
    "temp_spc = pd.concat([dummie,spc],axis=1)\n",
    "temp_spc.replace('?',np.NaN,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for weight\n",
    "weight_null = temp_weight.loc[temp_weight['weight'].isnull()]\n",
    "weight_no_null = temp_weight.dropna()\n",
    "wei_train_x = weight_no_null.iloc[:,:-1]\n",
    "wei_train_y = weight_no_null.iloc[:,-1:]\n",
    "wei_test_x = weight_null.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "# Train the model using the training sets\n",
    "regr.fit(wei_train_x, wei_train_y)\n",
    "# Make predictions using the testing set\n",
    "wei_test_y = regr.predict(wei_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat the result to original dataset \n",
    "df_test_y = pd.DataFrame(wei_test_y)\n",
    "df_test_y.reset_index(drop=True, inplace=True)\n",
    "wei_test_x.reset_index(drop=True, inplace=True)\n",
    "result = pd.concat([wei_test_x,df_test_y],axis=1)\n",
    "result.rename(index=str, columns={0: \"weight\"},inplace=True)\n",
    "result=result.append(weight_no_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: by argument to sort_index is deprecated, please use .sort_values(by=...)\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#add player_code colunm\n",
    "id_ply = df[['id_num','player_code']]\n",
    "result = result.join(id_ply.set_index('id_num'),on='id_num')\n",
    "result.sort_index(by='id_num')\n",
    "result.set_index('id_num',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split set by player_code\n",
    "result['player_code'].replace('?',np.NaN,inplace=True)\n",
    "code_null = result.loc[result['player_code'].isnull()]\n",
    "code_no_null = result.dropna()\n",
    "code_train_x = code_no_null.iloc[:,:-1]\n",
    "code_train_y = code_no_null.iloc[:,-1:]\n",
    "code_test_x = code_null.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncoder to mover_specialty\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(code_train_y['player_code'])\n",
    "trans=le.transform(code_train_y['player_code']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn prediction\n",
    "n_neighbors = 15\n",
    "ply_knn = neighbors.KNeighborsClassifier(n_neighbors, weights=\"distance\")\n",
    "ply_knn.fit(code_train_x, trans)\n",
    "ply_pre_knn=ply_knn.predict(code_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: by argument to sort_index is deprecated, please use .sort_values(by=...)\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#add predict row to original one\n",
    "pre=np.around(ply_pre_knn)\n",
    "pre = pre.astype('int64')\n",
    "pre_y=le.inverse_transform(pre)\n",
    "code_test_x['player_code'] = pre_y\n",
    "result=code_no_null.append(code_test_x)\n",
    "result = result.sort_index(by='id_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data split with move_specialty \n",
    "id_spc = df['move_specialty']\n",
    "result = result.join(id_spc,on='id_num')\n",
    "result['move_specialty'].replace('?',np.NaN,inplace=True)\n",
    "spc_null = result.loc[result['move_specialty'].isnull()]\n",
    "spc_no_null = result.dropna()\n",
    "spc_train_x = spc_no_null.iloc[:,:-2]\n",
    "spc_train_y = spc_no_null.iloc[:,-1:]\n",
    "spc_test_x = spc_null.iloc[:,:-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncoder to mover_specialty\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "le1.fit(spc_train_y['move_specialty'])\n",
    "trans_spc=le1.transform(spc_train_y['move_specialty'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn prediction\n",
    "n_neighbors = 15\n",
    "clf_knn = neighbors.KNeighborsClassifier(n_neighbors, weights=\"distance\")\n",
    "clf_knn.fit(spc_train_x, trans_spc)\n",
    "pre_knn=clf_knn.predict(spc_test_x)\n",
    "pre_knn_in=le1.inverse_transform(pre_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#add predict row to original one\n",
    "spc_test_x['move_specialty'] = pre_knn_in\n",
    "spc_test_x['player_code'] = spc_null['player_code']\n",
    "result=spc_no_null.append(spc_test_x)\n",
    "result.sort_index(by='id_num')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Any other Pre-processing Used. (Give the name along with the code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummie again\n",
    "ply_and_spc = ['player_code','move_specialty']\n",
    "dummie_ag = pd.get_dummies(result[ply_and_spc])\n",
    "result = pd.concat([result,dummie_ag],axis=1)\n",
    "result=result.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the final dataset is a 99002 rows × 190 columns and called result\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1:\n",
    "Model Name:-----------<br>\n",
    "Evaluation method and metric used Name:-----------<br>\n",
    "Name of the Hyperparameter used:--------------......<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2:\n",
    "Model Name:-----------<br>\n",
    "Evaluation method and metric used Name:-----------<br>\n",
    "Name of the Hyperparameter used:--------------......<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3:\n",
    "Model Name:-----------<br>\n",
    "Evaluation method and metric used Name:-----------<br>\n",
    "Name of the Hyperparameter used:--------------......<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART III: Best Hypothesis:\n",
    "Model Name:------------<br>\n",
    "Reason:--------------<br>\n",
    "Hyper-parameter Value:-----------<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
